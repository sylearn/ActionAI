import json
import os
import sys
import tiktoken
from typing import List,Dict,Any
from dotenv import load_dotenv
import time

# ç¯å¢ƒå˜é‡åŠ è½½
def load_env_files(seconds: int = 3):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶
    ä¼˜å…ˆåŠ è½½é€šç”¨.envæ–‡ä»¶ï¼Œç„¶åæ ¹æ®ç³»ç»ŸåŠ è½½ç‰¹å®šçš„ç¯å¢ƒå˜é‡æ–‡ä»¶
    ç‰¹å®šç³»ç»Ÿçš„ç¯å¢ƒå˜é‡ä¼šè¦†ç›–é€šç”¨ç¯å¢ƒå˜é‡
    """
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"è„šæœ¬ä½ç½®: {os.path.dirname(os.path.abspath(__file__))}")
    print(f"å…¥å£è„šæœ¬: {sys.argv[0]}")
    
    # è·å–å…¥å£è„šæœ¬æ‰€åœ¨çš„ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„
    if getattr(sys, 'frozen', False):
        base_path = os.path.dirname(sys.executable)
    else:
        # ä½¿ç”¨å…¥å£è„šæœ¬çš„ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„
        base_path = os.path.dirname(os.path.abspath(sys.argv[0]))
    
    print(f"æœ€ç»ˆä½¿ç”¨çš„åŸºç¡€è·¯å¾„: {base_path}")
    
    loaded_files = []  # è®°å½•åŠ è½½çš„æ–‡ä»¶ä¿¡æ¯
    
    # é¦–å…ˆå°è¯•åŠ è½½é€šç”¨.envæ–‡ä»¶
    common_env = os.path.join(base_path, '.env')
    if os.path.exists(common_env):
        before_vars = set(os.environ.keys())
        load_dotenv(common_env)
        after_vars = set(os.environ.keys())
        new_vars = after_vars - before_vars
        loaded_files.append({
            "type": "é€šç”¨é…ç½®",
            "path": common_env,
            "vars_count": len(new_vars),
            "status": "å·²åŠ è½½"
        })
    
    # ç„¶åæ ¹æ®ç³»ç»ŸåŠ è½½ç‰¹å®šçš„ç¯å¢ƒå˜é‡æ–‡ä»¶
    system_type = "Windows" if sys.platform == "win32" else "MacOS/Linux"
    system_env = os.path.join(
        base_path,
        '.env_win' if sys.platform == "win32" else '.env_mac'
    )
    if os.path.exists(system_env):
        before_vars = set(os.environ.keys())
        load_dotenv(system_env, override=True)
        after_vars = set(os.environ.keys())
        new_vars = after_vars - before_vars
        loaded_files.append({
            "type": f"{system_type}é…ç½®",
            "path": system_env,
            "vars_count": len(new_vars),
            "status": "å·²åŠ è½½"
        })
    
    # å¿…éœ€é…ç½®æ£€æŸ¥
    required_vars = {
        "MODEL": "æ¨¡å‹é€‰æ‹©",
        "OPENAI_API_KEY": "APIå¯†é’¥"
    }
    
    # å¯é€‰é…ç½®
    optional_vars = {
        "OPENAI_BASE_URL": ("APIåŸºç¡€URL", "https://api.openai.com/v1"),
        "MAX_TOKENS": ("æœ€å¤§ä»¤ç‰Œæ•°", "4096"),
        "TEMPERATURE": ("æ¸©åº¦ç³»æ•°", "0.7"),
        "STREAM": ("æµå¼è¾“å‡º", "True"),
        "DEBUG": ("è°ƒè¯•æ¨¡å¼", "False"),
        "IS_FUNCTION_CALLING": ("å·¥å…·è°ƒç”¨", "True"),
        "TIMEOUT": ("è¶…æ—¶æ—¶é—´", "300"),
        "MAX_MESSAGES": ("æœ€å¤§æ¶ˆæ¯æ•°", "100"),
        "MAX_MESSAGES_TOKENS": ("æœ€å¤§ä»¤ç‰Œé™åˆ¶", "60000"),
        "MESSAGES_PATH": ("æ¶ˆæ¯å­˜å‚¨è·¯å¾„", "./messages"),
        "MCP_SERVER_CONFIG_PATH": ("æœåŠ¡å™¨é…ç½®", ""),
        "SYSTEM_PROMPT": ("ç³»ç»Ÿæç¤ºè¯", ""),
        "PYTHON_PATH": ("Pythonè·¯å¾„", "python"),
        "NODE_PATH": ("Nodeè·¯å¾„", "node")
    }
    
    # æ˜¾ç¤ºå¿…éœ€é…ç½®çŠ¶æ€
    print("\nâ— å¿…éœ€é…ç½®æ£€æŸ¥:")
    all_required_set = True
    for var, desc in required_vars.items():
        value = os.getenv(var)
        if value:
            print(f"  âœ… {desc:<10} ({var}): å·²è®¾ç½®")
        else:
            all_required_set = False
            print(f"  âŒ {desc:<10} ({var}): æœªè®¾ç½®")
    
    # æ˜¾ç¤ºå¯é€‰é…ç½®çŠ¶æ€
    print("\nâš™ï¸  å¯é€‰é…ç½®çŠ¶æ€:")
    for var, (desc, default) in optional_vars.items():
        value = os.getenv(var)
        if value:
            print(f"  â„¹ï¸ {desc:<12} ({var}): {value}")
        else:
            print(f"  ğŸ’­ {desc:<12} ({var}): ä½¿ç”¨é»˜è®¤å€¼ [{default}]")
    
    # é…ç½®æ£€æŸ¥ç»“æœ
    print("\nğŸ“Š é…ç½®æ£€æŸ¥ç»“æœ:")
    if all_required_set:
        print("  âœ… æ‰€æœ‰å¿…éœ€é…ç½®å·²è®¾ç½®ï¼Œç³»ç»Ÿå¯ä»¥æ­£å¸¸å¯åŠ¨")
    else:
        print("  âŒ ç¼ºå°‘å¿…éœ€é…ç½®ï¼Œç³»ç»Ÿå¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
        print("  âš ï¸ è¯·æ£€æŸ¥ä¸Šè¿°æ ‡è®°ä¸ºæœªè®¾ç½®çš„å¿…éœ€é…ç½®é¡¹")
        
    if seconds > 0:
        # æ·»åŠ ä¸€ä¸ªç©ºè¡Œ
        print("\nâš™ï¸  æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...")
        for i in range(seconds, 0, -1):
            print(f"\râ³ {i} ç§’åç»§ç»­...", end="", flush=True)
            time.sleep(1)
        print("\n")  # æœ€åæ‰“å°ä¸€ä¸ªæ¢è¡Œ

def parse_mcp_servers(file_path):
    """
    è§£æMCPæœåŠ¡å™¨é…ç½®JSONæ–‡ä»¶ï¼Œæå–å‘½ä»¤å’Œå‚æ•°
    
    Args:
        file_path (str): JSONé…ç½®æ–‡ä»¶çš„è·¯å¾„
        
    Returns:
        dict: åŒ…å«æ¯ä¸ªæœåŠ¡å™¨çš„å‘½ä»¤å’Œå‚æ•°çš„å­—å…¸
    """
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
        # è¯»å–å¹¶è§£æJSONæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as file:
            config = json.load(file)
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«mcpServersé”®
        if 'mcpServers' not in config:
            raise KeyError("JSONæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°'mcpServers'é”®")
            
        # æå–æ¯ä¸ªæœåŠ¡å™¨çš„å‘½ä»¤å’Œå‚æ•°
        servers_info = {}
        for server_name, server_config in config['mcpServers'].items():
            # æå–å‘½ä»¤
            command = server_config.get('command', '')
            
            # æå–å‚æ•°
            args = server_config.get('args', [])
            
            # æå–ç¯å¢ƒå˜é‡
            env = server_config.get('env', {})
            # å­˜å‚¨æœåŠ¡å™¨ä¿¡æ¯
            servers_info[server_name] = {
                'command': command,
                'args': args,
                'env': env
            }
            
        return servers_info
        
    except json.JSONDecodeError as e:
        raise ValueError(f"JSONè§£æé”™è¯¯: {str(e)}")
    except Exception as e:
        raise Exception(f"è§£æMCPæœåŠ¡å™¨é…ç½®æ—¶å‡ºé”™: {str(e)}")

def get_server_command(servers_info, server_name):
    """
    è·å–æŒ‡å®šæœåŠ¡å™¨çš„å‘½ä»¤
    
    Args:
        servers_info (dict): æœåŠ¡å™¨ä¿¡æ¯å­—å…¸
        server_name (str): æœåŠ¡å™¨åç§°
        
    Returns:
        str: æœåŠ¡å™¨å‘½ä»¤
    """
    if server_name not in servers_info:
        raise KeyError(f"æœªæ‰¾åˆ°æœåŠ¡å™¨: {server_name}")
    
    return servers_info[server_name]['command']

def get_server_args(servers_info, server_name):
    """
    è·å–æŒ‡å®šæœåŠ¡å™¨çš„å‚æ•°
    
    Args:
        servers_info (dict): æœåŠ¡å™¨ä¿¡æ¯å­—å…¸
        server_name (str): æœåŠ¡å™¨åç§°
        
    Returns:
        list: æœåŠ¡å™¨å‚æ•°åˆ—è¡¨
    """
    if server_name not in servers_info:
        raise KeyError(f"æœªæ‰¾åˆ°æœåŠ¡å™¨: {server_name}")
    
    return servers_info[server_name]['args']

def get_server_env(servers_info, server_name):
    """
    è·å–æŒ‡å®šæœåŠ¡å™¨çš„ç¯å¢ƒå˜é‡
    
    Args:
        servers_info (dict): æœåŠ¡å™¨ä¿¡æ¯å­—å…¸
        server_name (str): æœåŠ¡å™¨åç§°
        
    Returns:
        dict: æœåŠ¡å™¨ç¯å¢ƒå˜é‡å­—å…¸
    """
    if server_name not in servers_info:
        raise KeyError(f"æœªæ‰¾åˆ°æœåŠ¡å™¨: {server_name}")
    
    return servers_info[server_name]['env']

def get_all_server_names(servers_info):
    """
    è·å–æ‰€æœ‰æœåŠ¡å™¨åç§°
    
    Args:
        servers_info (dict): æœåŠ¡å™¨ä¿¡æ¯å­—å…¸
        
    Returns:
        list: æœåŠ¡å™¨åç§°åˆ—è¡¨
    """
    return list(servers_info.keys())

def get_token_count(message: List[Dict[str, Any]], model: str) -> tuple[int, int, int, int]:
    """
    è®¡ç®—å¤šè½®å¯¹è¯ä¸­çš„tokenæ¶ˆè€—
    
    Args:
        message: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯åŒ…å«roleå’Œcontent
        model: æ¨¡å‹åç§°
        
    Returns:
        tuple: (total_input_tokens, total_output_tokens, current_input_tokens)
        - total_input_tokens: æ‰€æœ‰è½®æ¬¡çš„è¾“å…¥tokenæ€»å’Œ
        - total_output_tokens: æ‰€æœ‰è½®æ¬¡çš„è¾“å‡ºtokenæ€»å’Œ
        - current_input_tokens: å¦‚æœå¼€å§‹æ–°çš„å¯¹è¯è½®æ¬¡ï¼Œå½“å‰æ‰€æœ‰æ¶ˆæ¯å°†äº§ç”Ÿçš„è¾“å…¥tokenæ•°
    """
    # å°è¯•å¯¼å…¥tiktokenæ‰©å±•æ¨¡å—ï¼Œè§£å†³æ‰“åŒ…åæ‰¾ä¸åˆ°ç¼–ç çš„é—®é¢˜
    import tiktoken_ext
    import tiktoken_ext.openai_public
        
    # å§‹ç»ˆä½¿ç”¨cl100k_baseç¼–ç ï¼Œä¸ä½¿ç”¨modelå‚æ•°
    encoding = tiktoken.get_encoding("cl100k_base")
    
    total_input_tokens = 0
    total_output_tokens = 0
    current_input_tokens = 0
    
    # æ‰¾åˆ°æ‰€æœ‰useræ¶ˆæ¯çš„ç´¢å¼•ï¼Œç”¨äºåˆ’åˆ†å¯¹è¯è½®æ¬¡
    user_indices = [i for i, msg in enumerate(message) if msg["role"] == "user"]
    # è®¡ç®—å·²ç»å¯¹è¯çš„è½®æ¬¡
    round_count = len(user_indices)
    
    for round_idx, user_idx in enumerate(user_indices):
        # è®¡ç®—å½“å‰è½®æ¬¡çš„èŒƒå›´
        round_start = user_idx
        round_end = user_indices[round_idx + 1] if round_idx + 1 < len(user_indices) else len(message)

        # å°†userä¹‹å‰çš„æ‰€æœ‰æ¶ˆæ¯è®¡å…¥input tokens
        for msg in message[:round_start]:
            tokens = encoding.encode(msg["content"])
            total_input_tokens += len(tokens)
            if msg["role"] == "assistant" and "function_call" in msg:
                function_tokens = encoding.encode(json.dumps(msg["function_call"]))
                total_input_tokens += len(function_tokens)
    
        # å½“å‰è½®æ¬¡çš„useræ¶ˆæ¯è®¡å…¥input tokens
        user_tokens = encoding.encode(message[user_idx]["content"])
        total_input_tokens += len(user_tokens)
    
        # å½“å‰è½®æ¬¡userä¹‹åçš„assistantæ¶ˆæ¯è®¡å…¥output tokens
        for msg in message[round_start + 1:round_end]:
            if msg["role"] == "assistant":
                content_tokens = encoding.encode(msg["content"])
                total_output_tokens += len(content_tokens)
                # å¦‚æœåŒ…å«function callï¼Œè¦è®¡å…¥output tokens
                if "function_call" in msg:
                    function_tokens = encoding.encode(json.dumps(msg["function_call"]))
                    total_output_tokens += len(function_tokens)

    # è®¡ç®—current_input_tokensï¼ˆæ‰€æœ‰å½“å‰æ¶ˆæ¯çš„tokenæ•°ï¼‰
    for msg in message:
        tokens = encoding.encode(msg["content"])
        current_input_tokens += len(tokens)
        if msg["role"] == "assistant" and "function_call" in msg:
            function_tokens = encoding.encode(json.dumps(msg["function_call"]))
            current_input_tokens += len(function_tokens)

    return total_input_tokens, total_output_tokens, current_input_tokens, round_count

if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    message = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
        {"role": "user", "content": "ç¬¬ä¸€è½®é—®é¢˜"},
        {"role": "assistant", "content": "ç¬¬ä¸€è½®å›ç­”"},
        {"role": "user", "content": "ç¬¬äºŒè½®é—®é¢˜"},
        {"role": "assistant", "content": "ç¬¬äºŒè½®å›ç­”", 
         "function_call": {"name": "test", "arguments": "{}"}}
    ]
    input_tokens, output_tokens, current_tokens = get_token_count(message, "gpt-4")
    print(f"Total input tokens: {input_tokens}")
    print(f"Total output tokens: {output_tokens}")
    print(f"Current input tokens (for next round): {current_tokens}")